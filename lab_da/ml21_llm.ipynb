{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4HB6zhyFs1aHmRakabXv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JakeOh/202505_BD50/blob/main/lab_da/ml21_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM(Large Language Model, 거대 언어 모델)"
      ],
      "metadata": {
        "id": "N-kdNyrT6Hqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   시퀀스-시퀀스 작업(Sequence-to-Sequence)\n",
        "    *   시퀀스 데이터를 입력받아서 시퀀스 데이터를 출력하는 작업\n",
        "    *   자연어 처리(NLP, Natural Language Processing) 분야에서 요약, 번역 등의 작업 해당\n",
        "    *   두 개의 (순환) 신경망을 연결한 인코더-디코더(encoder-decoder) 구조가 널리 사용\n",
        "*   어텐션 메커니즘(Attention mechanism)\n",
        "    *   인코더-디코더 구조에서 사용된 순환 신경망의 성능을 향상시키기 위해서 고안\n",
        "    *   기존에는 인코더의 마지막 타임스텝에서 출력한 은닉 상태만을 사용해서 디코더가 새로운 텍스트를 생성\n",
        "    *   어텐션 메커니즘은 모든 타임스텝에서 인코더가 출력한 은닉 상태를 디코더가 참조할 수 있도록 고안\n",
        "    *   디코더가 새로운 토큰을 생성할 때 인코더가 처리한 토큰들 중에서 어떤 토큰에 주의(attention)를 기울일 지를 결정. (입력 토큰들마다 디코더가 중요도를 다르게 부여)\n",
        "*   트랜스포머 모델(Transformer model)\n",
        "    *   어텐션 메커니즘을 기반으로 하여 인코더-디코더 구조에서 순환층을 제거\n",
        "    *   인코더에서 한 번에 하나의 토크씩 처리하지 않고 입력 테스트 전체를 한 번에 처리\n",
        "    *   핵심 구성 요소\n",
        "        *   멀티 헤드 어텐션(multi-head attention)\n",
        "        *   층 정규화(layer normalization)\n",
        "        *   잔차 연결(residual connection)\n",
        "        *   피드 포워드 네트워크(feed-forward network)"
      ],
      "metadata": {
        "id": "ccV_u3Gn6OrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://pbs.twimg.com/media/GJg3QtMXwAAvUT4?format=jpg&name=large\"\n",
        "    alt=\"LLM 가계도\" />"
      ],
      "metadata": {
        "id": "lpSwQcdLAik9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Encoder 기반 모델\n",
        "    *   텍스트 (긍정/부정) 분류\n",
        "    *   개체명 인식 - 텍스트에서 사람 이름, 지역 이름, 회사 이름 등의 고유 명사를 식별.\n",
        "    *   BERT, RoBERTa, ...\n",
        "*   Encoder-Decoder 기반 모델\n",
        "    *   문서 요약, 번역, 질문-답변(질문과 문맥 텍스트가 주어졌을 때 문맥 안에서 답을 찾아서 생성)\n",
        "    *   T5, BART, ...\n",
        "*   Decoder 기반 모델\n",
        "    *   텍스트 생성 - 챗봇, 질문 답변, 요약, 번역\n",
        "    *   디코더:\n",
        "        *   이전까지 생성한 텍스트를 입력받아 다음 토큰을 예측하는 방식\n",
        "        *   인코더로부터의 입력이 없으면 디코더는 아무것도 생성할 수 없음.\n",
        "        *   이전에 생성한 텍스트인 것처럼 어떤 텍스트를 입력해 주면 인코더 도움 없이 다음 토큰을 예측.\n",
        "        *   프롬프트(prompt): 이전에 생성한 텍스트인 것처럼 전달하는 초기 텍스트.\n",
        "    *   GPT-4, GPT-5, LLaMA, ...\n",
        "    *   현재 가장 활발히 연구되고 있는 LLM 분야."
      ],
      "metadata": {
        "id": "sda7uyojGsLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HuggingFace에서 KoBART 모델 사용하기"
      ],
      "metadata": {
        "id": "xHlMq835MqdN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uNc23VAu6Dvk"
      },
      "outputs": [],
      "source": [
        "import transformers  # HuggingFace를 사용하기 위한 패키지"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HuggingFace에서 오픈 소스로 공개된 모델을 다운로드해서 로컬에서 실행할 수 있도록 해줌.\n",
        "pipe = transformers.pipeline(task=\"summarization\",  # 문서 요약 작업\n",
        "                             model=\"sshleifer/distilbart-cnn-12-6\",  # 모델\n",
        "                             device=0)  # device=0: GPU 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULsqrEDMNDe-",
        "outputId": "22536fa6-3348-40a1-cfa7-b6fc3b683e0c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    }
  ]
}